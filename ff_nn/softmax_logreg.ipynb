{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Logistic Regression\n",
    "Multinomial logistic regression (for more than 2 classes), but still, each sample can only belong to one class.\n",
    "\n",
    "## The Model\n",
    "<img src=\"pics/softmax.png\">\n",
    "\n",
    "## The Data\n",
    "Make sure, it also works for separating the two Gaussian clouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # Total number of samples\n",
    "N_0 = int(N/2) # number of samples for class 0\n",
    "N_1 = int(N/2) # number of samples for class 1\n",
    "D = 2 # number of features/dimensions\n",
    "K = 2 # number of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_0 = [-2,-2]\n",
    "variance = 1\n",
    "\n",
    "mu_1 = [2,2]\n",
    "\n",
    "m_cov = [[variance, 0],\n",
    "         [0, variance]]\n",
    "np.random.seed(41) # make the results reproducible\n",
    "X = np.concatenate([np.random.multivariate_normal(mu_0, m_cov, N_0),\n",
    "                    np.random.multivariate_normal(mu_1, m_cov, N_1)],\n",
    "                   axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target labels (indicator matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.zeros((N, K))\n",
    "T[0:N_0,0]=1\n",
    "T[N_0:,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_T = np.argmax(T, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Feed-Forward Pass\n",
    "Initialise random weights and bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31)\n",
    "Winitial = np.random.randn(D, K)\n",
    "binitial = np.random.randn(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(Xi, Wi, bi):\n",
    "    Z = Xi.dot(Wi) + bi\n",
    "    expZ = np.exp(Z)\n",
    "    return expZ / expZ.sum(axis=1, keepdims=True) # (np.exp(Z).T / np.sum(np.exp(Z),axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = forward(X, Winitial, binitial)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(Y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds == pred_T)/len(T)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Loss Function\n",
    "Multinomial logistic regression has a slightly different loss function than binary logistic regression because it uses the softmax rather than the sigmoid classifier. Consider for all training samples $\\{x_n\\}$ and classes k:\n",
    "$t_{nk} = 1$ if the target for sample $n$ is of class $k$ and $=0$ otherwise. \n",
    "\n",
    "$$L_{\\mathbf{W}, b} \\stackrel{\\text{def}}{=} \\prod_{n=1}^N \\prod_{k=1}^K y_{nk}^{\\ \\Large t_{nk}}$$\n",
    "\n",
    "The Loss to be minimised is the negative log-likelihood, also called Categorical Cross Entropy Loss:\n",
    "\n",
    "$$L_{CE}\\stackrel{\\text{def}}{=} - \\sum_{n=1}^N \\sum_{k=1}^K t_{nk} \\log y_{nk} $$\n",
    "\n",
    "If the more $y_{nk}$ is wrong, the larger the loss: Consider just 1 sample:\n",
    "\n",
    "* Exactly right $\\; \\rightarrow \\; L_{CE}=0$\n",
    "* 50\\% probability on correct target $\\; \\rightarrow \\; L_{CE}=-1*\\cdot\\log(0.5)=0.693$\n",
    "* 25\\% probability on correct target $\\; \\rightarrow \\; L_{CE}=-1*\\cdot\\log(0.25)=1.386$\n",
    "* 0\\% probability on correct target $\\; \\rightarrow \\; L_{CE}=-1*\\cdot\\log(0)=\\infty$\n",
    "\n",
    "\n",
    "Or maximise the the log-likelihood:\n",
    "\n",
    "$$J = \\sum_{n=1}^N \\sum_{k=1}^K t_{nk} \\log y_{nk}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cross_entropy_loss(Ti, Yi):\n",
    "    return -np.sum(Ti*np.log(Yi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.19436480213216"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cross_entropy_loss(T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "There is no closed-form solution for the optimal $W$ in softmax logistic regression $\\rightarrow$ find the partial derivaties of $J$ with respect to the $W_{dk}$ and perform gradient descent.\n",
    "\n",
    "$$z=W^Tx+b$$\n",
    "$$y=softmax(z)$$\n",
    "$$y_{nk} = \\frac{e^{z_{nk}}}{\\sum_{j=1}^K e^{z_{nj}}}$$\n",
    "\n",
    "When deriving the partial derivative of $J$ with respect to $W_{dk}$ one has to consider the particular structure of the softmax function: Each $y_{nk}$ is a function of all $\\{ a_{k'} \\}_{1}^K$, each of which in turn is a function of $W_{dk}$. Hence the additional dummy variable $k'$ in:\n",
    "$$\\frac{\\partial J}{\\partial W_{dk}} = \\sum_{n=1}^N \\sum_{i=1}^K \\frac{\\partial J_{nk'}}{\\partial y_{nk'}} \\frac{\\partial y_{nk'}}{\\partial z_{nk}} \\frac{\\partial z_{nk}}{\\partial W_{dk}}$$\n",
    "\n",
    "$$\\frac{\\partial J_{nk'}}{\\partial y_{nk'}} = \\frac{t_{nk'}}{y_{nk'}}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial y_{nk'}}{\\partial z_{nk}} &= (-1)  e^{z_{nk'}} \\left(\\sum_j e^{z_{nj}}\\right)^{-2}  e^{z_{nk}} \\; \\; \\; \\; \\text{if} \\; k'\\neq k\\\\\n",
    "&= (-1) \\frac{e^{z_{nk'}}}{\\sum_j e^{z_{nj}}} \\frac{e^{z_{nk}}}{\\sum_j e^{z_{nj}}}\\\\\n",
    "&= -y_{nk'}y_{nk}\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial y_{nk'}}{\\partial z_{nk}} &=  e^{z_{nk'}} \\left(\\sum_j e^{z_{nj}}\\right)^{-1} -  e^{z_{nk'}} \\left(\\sum_j e^{z_{nj}}\\right)^{-2} e^{z_{nk}} \\; \\; \\; \\; \\text{if} \\; k'= k\\\\\n",
    "&= y_{nk'}(1-y_{nk}) \\; \\; \\; \\; \\text{although} \\; k=k'\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "with\n",
    "$$\\begin{aligned}\n",
    "\\delta_{kk'} &= 1 \\; \\; \\; \\; \\text{if} \\; k'= k \\\\\n",
    "\\delta_{kk'} &= 0 \\; \\; \\; \\; \\text{if} \\; k'\\neq k\n",
    "\\end{aligned}$$\n",
    "the expression simplifies to\n",
    "$$\\frac{\\partial y_{nk'}}{\\partial z_{nk}} = y_{nk'}(\\delta_{kk'}-y_{nk})$$\n",
    "\n",
    "\n",
    "$$z_{nk} = W_{:,k}^{T}x_n + b_k$$\n",
    "$$\\frac{\\partial z_{nk}}{\\partial W_{dk}} = x_{nd}$$\n",
    "\n",
    "combine and simplify\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial W_{dk}} &= -\\sum_{n=1}^N \\sum_{i=1}^K \\frac{t_{ni}}{y_{ni}} y_{ni}(\\delta_{ki}-y_{nk}) x_{nd}\\\\\n",
    "&= -\\sum_{n=1}^N \\sum_{i=1}^K t_{ni}(\\delta_{ki}-y_{nk}) x_{nd}\\\\\n",
    "&= -\\sum_{n=1}^N x_{nd}\\left( \\sum_{i=1}^K t_{ni}\\delta_{ki}- \\sum_{i=1}^K t_{ni} y_{nk} \\right)\\\\\n",
    "&= -\\sum_{n=1}^N \\left(t_{nk} - y_{nk}\\right) x_{nd}\n",
    "\\end{aligned}$$\n",
    "\n",
    "In matrix form:\n",
    "$$\\nabla_{W} J=X^T(T-Y)$$\n",
    "\n",
    "In code - gradient of the categorical cross-entropy loss (flipped sign):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_w(Xi, Ti, Yi):\n",
    "    return Xi.T.dot(Yi-Ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial derivative with respect to bias term of class $k$:\n",
    "$$\\frac{\\partial J}{\\partial b_k} = \\sum_{n=1}^N \\sum_{i=1}^K \\frac{\\partial J_{ni}}{\\partial y_{ni}} \\frac{\\partial y_{ni}}{\\partial z_{nk}} \\frac{\\partial z_{nk}}{\\partial b_k}$$\n",
    "\n",
    "Realising that\n",
    "$$\\frac{\\partial z_{nk}}{\\partial b_k} = 1$$\n",
    "and plugging in the intermediate results from above:\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_k} = \\sum_{n=1}^N \\left(t_{nk}-y_{nk}\\right)$$\n",
    "\n",
    "In code (flipped sign):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_b(Ti, Yi):\n",
    "    return np.sum(Yi-Ti, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "lrate = 1e-4\n",
    "losses = []\n",
    "\n",
    "W = np.random.randn(D, K)\n",
    "b = np.random.randn(K)\n",
    "\n",
    "for i in range(iterations):\n",
    "    Y = forward(X, W, b)\n",
    "    loss = cat_cross_entropy_loss(T, Y)\n",
    "    losses.append(loss)\n",
    "    W = W - (lrate * grad_w(X, T, Y)) # minimise: follow the negative gradient\n",
    "    b = b -(lrate * grad_b(T, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11acdf898>]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19296432, -0.07953072],\n",
       "       [-1.14811897,  1.74749873]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(Y, axis=1) == pred_T)/len(T)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
